{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utrU3Ul7KK0G"
   },
   "source": [
    "# Mozilla DeepSpeech API Exploration\n",
    "\n",
    "Mozilla released [DeepSpeech 0.6](https://github.com/mozilla/DeepSpeech/releases/tag/v0.6.0) with [APIs in C, Java, .NET, Python, and JavaScript](https://deepspeech.readthedocs.io/en/v0.6.0/Python-API.html).\n",
    "\n",
    "From Colab menu, select: **Runtime** > **Change runtime type**, and verify that it is set to Python3, and select GPU if you want to try out GPU version.\n",
    "\n",
    "You can install DeepSpeech with pip (make it deepspeech-gpu==0.6.0 if you are using GPU in colab runtime):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8661,
     "status": "ok",
     "timestamp": 1582077297342,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "iemeuv-jKR3P",
    "outputId": "401b5c8a-dfaa-4012-c079-90f0cc47a11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10399,
     "status": "ok",
     "timestamp": 1582077310767,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "zABV65yhNJ0M",
    "outputId": "c79b9d70-b0b0-4680-f1c9-6cca11258fb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepspeech==0.6.0 in d:\\program\\winpython64-3760\\python-3.7.6.amd64\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy<=1.17.0,>=1.14.5 in d:\\program\\winpython64-3760\\python-3.7.6.amd64\\lib\\site-packages (from deepspeech==0.6.0) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "!{sys.executable} -m pip install deepspeech==0.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbWIPOUwNVyI"
   },
   "source": [
    "## Download Models and Audio Files\n",
    "\n",
    "Mozilla has released models for US English, we will use those in this code lab.\n",
    "\n",
    "1. **Download the models:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91329,
     "status": "ok",
     "timestamp": 1582077407963,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "rxa0os-3OA1X",
    "outputId": "ead56909-10fb-4554-e2ef-057696ed7f6d"
   },
   "outputs": [],
   "source": [
    "# Quick download go to URL: https://github.com/mozilla/DeepSpeech/releases\n",
    "# !curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4K-ikRBuOSoR"
   },
   "source": [
    "2. **Unzip the downloaded models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20972,
     "status": "ok",
     "timestamp": 1582077541484,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "aZ_0XlmMOjFA",
    "outputId": "a125216f-77e1-4ea5-b061-21a5fbb4122c"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('deepspeech-0.6.0-models/'):\n",
    "    !tar -xvzf deepspeech-0.6.0-models.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_g5hZVWXO1wl"
   },
   "source": [
    "3. **Download audio data files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6550,
     "status": "ok",
     "timestamp": 1582077731960,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "C8r7m0zlO_BJ",
    "outputId": "0574d652-1725-436a-9a6a-2960fddfbae4"
   },
   "outputs": [],
   "source": [
    "# Quick download go to URL: https://github.com/mozilla/DeepSpeech/releases\n",
    "# !curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/audio-0.6.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4yZaht2PH_5"
   },
   "source": [
    "4. **Unzip audio files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5106,
     "status": "ok",
     "timestamp": 1582077761114,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "82DLg4JpPOVX",
    "outputId": "52335679-9452-4b5b-cb73-f884f0ea264d"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('audio/'):\n",
    "    !tar -xvzf audio-0.6.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIiwclaXPzfm"
   },
   "source": [
    "5. **Test that it all works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6026,
     "status": "ok",
     "timestamp": 1582077775981,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "KlXV9XlpP8k2",
    "outputId": "a88c7552-a998-4f4d-e70b-71e455e2a742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience proof less\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v1.14.0-21-ge77504ac6b\n",
      "DeepSpeech: v0.6.0-0-g6d43e21\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "2020-03-05 09:50:41.074283: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "Loading model from file deepspeech-0.6.0-models/output_graph.pb\n",
      "Loaded model in 2.13s.\n",
      "Loading language model from files deepspeech-0.6.0-models/lm.binary ./deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.14s.\n",
      "Running inference.\n",
      "Inference took 16.659s for 1.975s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/2830-3980-0043.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7229,
     "status": "ok",
     "timestamp": 1582077787063,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "YSENx8jhQGIS",
    "outputId": "1c1736c0-21e9-46bb-8121-defd508fb3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why should one halt on the way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v1.14.0-21-ge77504ac6b\n",
      "DeepSpeech: v0.6.0-0-g6d43e21\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "2020-03-05 09:51:03.813929: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "Loading model from file deepspeech-0.6.0-models/output_graph.pb\n",
      "Loaded model in 1.05s.\n",
      "Loading language model from files deepspeech-0.6.0-models/lm.binary ./deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.117s.\n",
      "Running inference.\n",
      "Inference took 20.643s for 2.735s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/4507-16021-0012.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7056,
     "status": "ok",
     "timestamp": 1582077795621,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "dSAovXUJQLjP",
    "outputId": "8174b8ae-9954-4114-e248-7c545d859488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your power is sufficient i said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v1.14.0-21-ge77504ac6b\n",
      "DeepSpeech: v0.6.0-0-g6d43e21\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "2020-03-05 09:51:26.006909: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "Loading model from file deepspeech-0.6.0-models/output_graph.pb\n",
      "Loaded model in 1.03s.\n",
      "Loading language model from files deepspeech-0.6.0-models/lm.binary ./deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.0131s.\n",
      "Running inference.\n",
      "Inference took 19.447s for 2.590s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/8455-210777-0068.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJT6z1-uQQZ1"
   },
   "source": [
    "Examine the output of the last three commands, and you will see results *“experience proof less”*, *“why should one halt on the way”*, and *“your power is sufficient i said”* respectively. You are all set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p61UrYSvQrOd"
   },
   "source": [
    "# DeepSpeech API\n",
    "\n",
    "1.   **Import deepspeech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKwSvpvaRFIe"
   },
   "outputs": [],
   "source": [
    "import deepspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqd6bQ_gRPOB"
   },
   "source": [
    "2. **Create a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKDVOmbFRR1A"
   },
   "outputs": [],
   "source": [
    "model_file_path = 'deepspeech-0.6.0-models/output_graph.pbmm'\n",
    "beam_width = 500\n",
    "model = deepspeech.Model(model_file_path, beam_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VNRxsb2zRgeJ"
   },
   "source": [
    "3. **Add language model for better accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1755,
     "status": "ok",
     "timestamp": 1582077816595,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "6FRX1EvDRnLH",
    "outputId": "2ef6b5be-1841-4224-b86c-fb575b9a8b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_file_path = 'deepspeech-0.6.0-models/lm.binary'\n",
    "trie_file_path = 'deepspeech-0.6.0-models/trie'\n",
    "lm_alpha = 0.75\n",
    "lm_beta = 1.85\n",
    "model.enableDecoderWithLM(lm_file_path, trie_file_path, lm_alpha, lm_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWbHnlwCRuDo"
   },
   "source": [
    "## Batch API\n",
    "\n",
    "1.   **Read an input wav file**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRshwTMoSFEL"
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "filename = 'audio/8455-210777-0068.wav'\n",
    "w = wave.open(filename, 'r')\n",
    "rate = w.getframerate()\n",
    "frames = w.getnframes()\n",
    "buffer = w.readframes(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAowLS39SNC_"
   },
   "source": [
    "Checkout sample rate and buffer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1792,
     "status": "ok",
     "timestamp": 1582077866927,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "NHvatdmxSYGu",
    "outputId": "3c965f8d-908f-4694-9908-129bb30ca372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "16000\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(rate)\n",
    "print(model.sampleRate())\n",
    "print(str(type(buffer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOhbO3iTS3ft"
   },
   "source": [
    "As you can see that the speech sample rate of the wav file is 16000hz, same as the model’s sample rate. But the buffer is a byte array, whereas DeepSpeech model expects 16-bit int array.\n",
    "\n",
    "2.  **Convert byte array buffer to int16 array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1772,
     "status": "ok",
     "timestamp": 1582077874104,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "XYXF6AU2S8m2",
    "outputId": "7305c9f2-64be-4196-eb99-6079fba0970e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# skip this step if you are streaming the audio\n",
    "import numpy as np\n",
    "data16 = np.frombuffer(buffer, dtype=np.int16)\n",
    "print(str(type(data16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yyIxzx1zTVFp"
   },
   "source": [
    "3.  **Run speech-to-text in batch mode to get the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3291,
     "status": "ok",
     "timestamp": 1582077881577,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "XdzZteC7TZDP",
    "outputId": "3c7c86d9-8fd1-4112-a166-b3197c8067bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your power is sufficient i said\n"
     ]
    }
   ],
   "source": [
    "# skip this step if you are streaming the audio\n",
    "text = model.stt(data16)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUCXp-5uTh0L"
   },
   "source": [
    "## Streaming API\n",
    "\n",
    "Now let’s accomplish the same using streaming API. It consists of 3 steps: open session, feed data, close session.\n",
    "\n",
    "1.  **Open a streaming session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMSQ2VYCTyao"
   },
   "outputs": [],
   "source": [
    "context = model.createStream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YK4QDAZtT3QZ"
   },
   "source": [
    "2.  **Repeatedly feed chunks of speech buffer, and get interim results if desired**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2831,
     "status": "ok",
     "timestamp": 1582077897988,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "ScS6c2QQT72-",
    "outputId": "f528b51a-22f1-493c-cf76-88ce88ea08d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i\n",
      "your power is\n",
      "your power is suffi\n",
      "your power is sufficient i said\n",
      "your power is sufficient i said\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "buffer_len = len(buffer)\n",
    "offset = 0\n",
    "batch_size = 16384\n",
    "text = ''\n",
    "while offset < buffer_len:\n",
    "    end_offset = offset + batch_size\n",
    "    chunk = buffer[offset:end_offset]\n",
    "    data16 = np.frombuffer(chunk, dtype=np.int16)\n",
    "    model.feedAudioContent(context, data16)\n",
    "    text = model.intermediateDecode(context)\n",
    "    print(text)\n",
    "    offset = end_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeV7x1NgUK-p"
   },
   "source": [
    "3.  **Close stream and get the final result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1745,
     "status": "ok",
     "timestamp": 1582077929260,
     "user": {
      "displayName": "Dennis Lee",
      "photoUrl": "",
      "userId": "07448407159049887352"
     },
     "user_tz": -480
    },
    "id": "aS0WtnF5UM4n",
    "outputId": "89b345aa-dab1-4ba5-9b5b-4367acd91d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your power is sufficient i said\n"
     ]
    }
   ],
   "source": [
    "text = model.finishStream(context)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-vbd5CmUmsY"
   },
   "source": [
    "Verify that the output is same as as the batch API output: \"your power is sufficient i said.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVNGdkq0fV-n"
   },
   "source": [
    "# Recap\n",
    "\n",
    "DeepSpeech has two modes: batch and streaming. First step is to create a model object, and then either call `stt()` or `feedAudioContnet()` to transcribe audio to text.\n",
    "<br/>\n",
    "\n",
    "---\n",
    "&copy; 2020 Satish Chandra Gupta"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "021deepspeech.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/scgupta/yearn2learn/blob/master/speech/asr/deepspeech06/mozilla_deepspeech_api_notebook.ipynb",
     "timestamp": 1582077174147
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
